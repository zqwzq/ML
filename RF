##################################################################
## The data is read and randomly divided 7:3 into training sets and test sets
## Reading data.
data <- read.xlsx("data.xlsx")
## Select the seed number to divide the data set. Note that the seed number of the partition data set cannot be changed.
set.seed(500)   
## 70% as the training set, 30% as the test set
index <- createDataPartition(data$SOC,p = 0.7)   
test_data <- data[-index$Resample1,]
train_data <- data[index$Resample1,]
##################################################################
## The mesh is defined and the optimal parameters are adjusted by grid search method
## Set 10 fold cross validation
rfcontrol <- trainControl(method = "cv",number = 10, search="grid")   
## Set adjustment grid and spacing.
tune_grid <- expand.grid(mtry =seq(1,56,1))    
## Different parameters are used for machine learning modeling to find the optimal parameters
rfreg <- train(SOC ~., data = train_data, method = "rf",
                trControl = rfcontrol,tuneGrid = tune_grid, verbose = FALSE)    
## Print the optimal parameter combination
rfreg$bestTune          

##################################################################
## Use different seed numbers to build machine learning models, and output precision indicators of training sets and test sets. Refer to Step C in README for details.
## Define a machine learning function for a multi-seed loop
RF_func <- function(seed){        
## Model with different seed numbers
set.seed(seed)     
## Set 10 fold cross validation
control <- trainControl(method = "cv",number = 10, search="grid")   
tune_grid <- expand.grid(mtry = rfreg$bestTune)   
## The optimal parameters are used as the model parameters for machine learning modeling
rfreg <- train(SOC ~., data = train_data, method = "rf",
                trControl = control,tuneGrid = tune_grid,
                verbose = FALSE)       
## The established machine learning model is used to predict the test set data
yp <- predict(rfreg,newdata = test_data)   
## Extract the measured data of the test set
y <- test_data$SOC          
Sregg=sum((yp-mean(y))^2)
Stott=sum((mean(y)-y)^2)
Sress=sum((yp-y)^2)
## Calculate the accuracy index R2 of the test set
test_rsquared=Sregg/Stott
## Calculate the accuracy index MAE of the test set
test_mae= sum(abs(yp-y))/ 32
## Calculate the accuracy index RMSE of the test set
test_rmse = sqrt(  (sum((yp-y)^2))  /32  )     
## Calculate the accuracy index RPD of the test set
test_rpd <- sd(test_data[,1])/test_rmse
## Calculate the accuracy index nRMSE of the test set
test_nrmse <- test_rmse/(max(test_data[,1])-min(test_data[,1]))
## Calculate the accuracy index RPD of the train set
train_rpd <- sd(train_data[,1])/rfreg$results$RMSE
## Extract the nRMSE of the model
train_nrmse <- rfreg$results$RMSE/(max(train_data[,1])-min(train_data[,1])) 
## Returns each precision indicator of the model
return(c(rfreg$results$RMSE,rfreg$results$Rsquared,
           rfreg$results$MAE,train_rpd,train_nrmse,
           test_rmse,test_rsquared,test_mae,test_rpd,test_nrmse))}   
## Sets the number of seeds to use for machine learning modeling
seed <- seq(10000,11000,10)    
## The number of seed number is extracted and used to calculate the average value of precision index
n <- length(seed)    
## The set number of seeds is applied for circular machine learning modeling
zhibiao_list <- lapply(seed, RF_func)    
## Define a matrix for storing precision indicators and calculating average values
zhibiao <- matrix(as.numeric(unique(unlist(zhibiao_list))),nrow = n, ncol = 10, byrow = TRUE)   
## Output the RMSE of the training set
sprintf("Train_RF_RMSE is ：%f",mean(zhibiao[,1]))   
## Output the R2 of the training set
sprintf("Train_RF_R2 is ：%f",mean(zhibiao[,2]))   
## Output the MAE of the training set
sprintf("Train_RF_MAE is ：%f",mean(zhibiao[,3]))   
## Output the RPD of the training set
sprintf("Train_RF_RPD is ：%f",mean(zhibiao[,4]))   
## Output the nRMSE of the training set
sprintf("Train_RF_nRMSE is ：%f",mean(zhibiao[,5]))  
## Output the RMSE of the test set
sprintf("Test_RF_RMSE is ：%f",mean(zhibiao[,6]))   
## Output the R2 of the test set
sprintf("Test_RF_R2 is ：%f",mean(zhibiao[,7]))   
## Output the MAE of the test set
sprintf("Test_RF_MAE is ：%f",mean(zhibiao[,8]))   
## Output the RPD of the test set
sprintf("Test_RF_RPD is ：%f",mean(zhibiao[,9]))   
## Output the nRMSE of the test set
sprintf("Test_RF_nRMSE is ：%f",mean(zhibiao[,10]))   


##################################################################
## The built model is used to predict the data of the test set, and 1:1 line mapping is performed with the measured values of the test set, which is used to intuitively compare the prediction performance of the model
## Use different seed numbers to build machine learning models, and output dependent variable of test sets. Refer to Step D in README for details.
RF_func <- function(seed){                       
## Model with different seed numbers
set.seed(seed)    
## Set 10 fold cross validation
control <- trainControl(method = "cv",number = 10, search="grid")    
tune_grid <- expand.grid(mtry = rfreg$bestTune)
## The optimal parameters are used as the model parameters for machine learning modeling
rfreg <- train(SOC ~., data = train_data, method = "rf",
                trControl = control,tuneGrid = tune_grid,
                verbose = FALSE)   
## The established machine learning model is used to predict the test set data
yp <- predict(rfreg,newdata = test_data)   
##  Convert the predicted test set dependent variable to data frame format
yp <- as.data.frame(yp)   
return(yp)
}
## Sets the number of seeds to use for machine learning modeling. Consistent with modeling.
seed <- seq(10000,11000,10) 
## The number of seed number is extracted and used to calculate the average value of precision index
n <- length(seed)  
## The set number of seeds is applied for circular machine learning modeling
ypall <- lapply(seed, RF_func)    
##  Initializes a variable to hold the predicted test set dependent variable
total <- 0   
##  Add up the results of each run
for (i in 1:n) {
  total <-total+ypall[[i]]
}    
## Gets the average of multiple model predictions
ypall_mean <- total/n


##################################################################
## The SOC content of the whole study area is predicted, that is, the independent variable values of each pixel are brought into the established model to predict SOC, see step F in README
RF_func <- function(seed){                       
## Model with different seed numbers
set.seed(seed)    
## Set 10 fold cross validation
control <- trainControl(method = "cv",number = 10, search="grid")    
tune_grid <- expand.grid(mtry = rfreg$bestTune)
## The optimal parameters are used as the model parameters for machine learning modeling
rfreg <- train(SOC ~., data = train_data, method = "rf",
                trControl = control,tuneGrid = tune_grid,
                verbose = FALSE)  
##The independent variable value of each pixel is brought into the model to predict the SOC value of each pixel
fanyan_yp <- predict(rfreg,newdata = fanyan_data)   
##  Convert the SOC value to data frame format
fanyan_yp <- as.data.frame(fanyan_yp)
return(fanyan_yp)
}
## Sets the number of seeds to use for machine learning modeling. Consistent with modeling.
seed <- seq(10000,11000,10)
## The number of seed number is extracted and used to calculate the average value of precision index
n <- length(seed)
## The set number of seeds is applied for circular machine learning modeling
fanyan_ypall <- lapply(seed, RF_func)
##  Initializes a variable to hold the predicted SOC value
total <- 0
##  Add up the results of each run
for (i in 1:n) {
  total <-total+fanyan_ypall[[i]]
}
## Gets the average of multiple model predictions
fanyan_ypall_mean <- total/n
## Write out the inversion results
write.table(fanyan_ypall_mean,file = "FANYAN.txt",row.names = F,col.names = F)


##################################################################
## Evaluate the importance of each variable in the prediction model, obtain the importance of 100 model cycles, and calculate the relative importance of each variable
RF_func <- function(seed){                       
## Model with different seed numbers
set.seed(seed)    
## Set 10 fold cross validation
control <- trainControl(method = "cv",number = 10, search="grid")    
tune_grid <- expand.grid(mtry = rfreg$bestTune)
## The optimal parameters are used as the model parameters for machine learning modeling
rfreg <- train(SOC ~., data = train_data, method = "rf",
                trControl = control,tuneGrid = tune_grid,
                verbose = FALSE)  
## Get the importance of each variable from the model
zhongyaoxing <- varImp(rfreg)[["importance"]]
  return(zhongyaoxing)
}
## Sets the number of seeds to use for machine learning modeling. Consistent with modeling.
seed <- seq(10000,11000,10)
## The number of seed number is extracted and used to calculate the average value of precision index
n <- length(seed)
## The set number of seeds is applied for circular machine learning modeling
zhongyaoxing_list <- lapply(seed, RF_func)
##  Initialize a variable to store the importance of each predictor
total <- 0
##  Add the importance of each variable for each loop
for (i in 1:n) {
  total <-total+zhongyaoxing_list[[i]]
}
##  The average value of variable importance is obtained by dividing the number of models
zhongyaoxing <- total/length(seed)
